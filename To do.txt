Read the maths of Mirror Descent

Look closer at iid sensing vectors and standard Gaussian Measurements  

Implement CDP measurements

Other Algos for Spectral Initialization

-----------------------------------------

Find a better error measure when dealing with complex sensing vectors (Fourier Transform) or images 

Implement complex derivatives of \f and \psi 

Test with zero-boundary real images + real matrix A first. 

Add some positive noise to the measurements: Poisson or Gaussian Noise

---------------------------------------------------------------

Read & compute & implement Wirtinger complex derivative of f and \psi. 
What do they mean? What behavior is to be expected from them? In the case of \psi for instance which is not complex differentiable.

-------------------------------------------------------------------

Implement FFT and compare with current DFT

Search Papers on Complex valued derivatives in Phase Retrieval.

Project in signal space to conform to some a-priori knowledge about its structure (signal is real-valued, nonnegative and spatially limited ?)

Solve the scaling error caused by the Wirtinger Flow

--------------------------------------------------------

Any Reformulation of the Bregman Divergence between two complex-valued images? What replaces the inequality between to complex Bregman divergences?
Find another gradient-descent check or reformulation of relative smoothness in the current complex setting.

--------------------------------------------------------
The next goal would be to find a way to get the error further down for complex objects. And yes, the non-matrix FFT that I still have to try.

---------------------------------------------------------------------------


Increase number of measurements: it does not even improve the reconstruction. 
The reason maybe that the sampling frequency (image discretizaion width ) is then too small (large or coarse) to capture high frequency Fourier components.
So choose the ratio carefully

Find a better distance-based stopping criterion that makes sense, once for all.

--------------------------------------------------------------------------

Implement FIENUP algorithm for comparison. 
Test with less symmetric fully-complex (: error gets drastic for those) images. 
See how to beneficially include Parseval's theorem 

------------------------------------------------------------------------------------------------------------

FIENUP is also stuck in local minima. Convergence of Mirror Descent is only local.(Imaginary part converges more slowly).
Add shrinkwrapping from the video https://www.youtube.com/watch?v=8rJYhRMVvQw  to improve FIENUP: Projecting each on the initial support might not be enough. So update the boundary by shrinkwrapping.

-------------------------------------------------------------
Big Problem : Algorithm does not move the Imaginary part, not even a bit. Thus the overall poor decay of the modulus of the Fourier Error. Iterate vanishes totally after some iterations. Check why 

---------------------------------------------------------------------

As the resolution increases, we still fit perfectly the data but the reconstruction gets poorer. Regularize.

--------------------------------------------------------------------------

odl kills imaginary part. Fix that

-------------------------------------------------------------------------------
Updates:

-Realistic Box constraints

Challenges: 

-Memory issues (image and matrix size). E.g. Unable to allocate 256. MiB for an array with shape (4096, 4096) and data type complex128
-SetUpImage kills first image

Outlook: 

-RAAR
-early stopping
-rescale fourth image
-Analytic FT

-shrinkwrapping, ellipse constraint
Poisson noise

- apply MAsk, TV, then data

--------------------------------------------------------------------------------
Observations: 

- With precise mask, one needs thousands of iterations to reconstructs something like the ground truth.
- Tuelwer's implementation ( meant only for real positive images) of FiENUP HIO seems to converge only when the initial guess fits the data.
   sometimes, even that is not sufficient (???)

--------------------------------------------------------------------------------

- What convergence to expect? 
- Proximal theory for DRS Analysis
- RMRS looks different and better than RSRM. Why? RSRM = HIO, RMRS = RAAR

---------------------------------------------------------------------------------
Outlook : 

-add a section on the FT (invariance properties after translation, rotation, ... ) and then, discuss the unicity problem of Fourier phase retrieval

-prove that HIO reconstructs real and radially symmetric images, with no need of support knowledge, but very sensitive to a non-constant noise in the magnitudes in the initialization (see ipad, FT)


Observations:

1-
A space shift (translation) is Fourier transformed into a phase-changed but norm-invariant measurement. 
So, losing the phase during CDI measurements does not delete the shape information of the signal, but only its location in space. 

The question is then how does the phase determine the image? 
In otherwords, are there visual similarities or transformations (a part from  translations and rotations)  between two images with thier FT having the same norm but different phases?

2-
If an image is real and symmetric, its FT has no phase (i.e. is real). Such images are then very easy to reconstruct

3-
HIO real can reconstruct real radially symmetric (rs) images, even with arbitrary initial magnitudes (from *real* initial image), but in few steps. More than needed diverges.

4-
Box constraint makes RAAR and HIO able to recover real and rs images, provided a real initialization. 
The box also seems to hinder HIO from wandering away from the true real image.
This effect was for some rare occasions not significant on complex images. 
First TV cleans up the reconstruction.

5-
Regarding the stopping criterion, with a noise level of l (= 10-1), and data size m (= 32*32), the loss function shouldn't drop below l^2 / 4*m  (= 10-5). 
Surprisingly, like HIO, RSRM stagnates around 10-3 even after 15k iterations. RSRM reconstructs best. (precise support is applied on the complex ring of Gaussian image )
Meanwhile, RAAR ( = RMRS ) did attain 10-5

6-
For inconsistency, I thought a single dot image (leading to constant 1 magnitudes ) corrupted by a strong noise, would do. Quite a deception.

Challenges: 

-Display takes too long

---------------------------------------------------------------------------------

Outlook:

-implement method from article 'construction of fixed points...' page 199. Strong convergence in the limit of 'regularizers' is expected. 

-prove fix point theorem

-implement HPR

-show weak convergence for nonexpansive mappings


Observations:

-Non convex analysis: If the constraint set is not convex, the projection can be expansive 

- The feasible set C ( norm(x) <= measurement + epsilon ) is actually a bounded convex and closed subset of L2. 
The update operator T would map C into itself if a norm-preserving operator, like the fourier transform is used.
The convex theory could then justify our (good) numerical results.   

-If T is compact, convergence of T_{\lambda} happens in norm


----------------------------------------------------------------------------------

Outlook:

-


Observations:

-real and symmetric images have 0 phase in Fourier space. They are well reconstructed because I chosed to project 0 as b, i.e. a number with phase 0. 
In principle, any other complex number on the circle of radius b is a projection of 0 onto the Fourier amplitudes constraint set. 

-An object diameter slightly less than half the grid length improves significantly the reconstuction (even with noise)

-oversampling in Fourier sapce (which amounts in 0-padding in object space) is crucial for reconstruction. 
Only then, do we have enough information on the signal to recover it.


Challenges: 

-Is random noise (present at high frequencies) appropriate? Have some proportionality. It helps improve noisy reconstruction
The larger the object's support, the less low frequencies are being sampled and the more pronounced is the Dirac pic at the origin, giving less strength to the noise.


----------------------------------------------------------------------------------

Outlook:
-still some work to improve Poisson DRS in OS (for local converge with noiseless Fourier data)
-test exact support (ellipse) for sheep logan, to avoid translations
-include M_TVS in RAAR
-test RAAR and include TV
-Don't correct phase for Poisson and observe

Observations:
-HIO retrieves reasonable images from Fourier data after 1000 iterations, HIO = AAR RSRM, but not AAR RMRS.  
-With Fourier data, one achieves only local convergence 
- TV1 and or Poisson DRS in OS are my best solvers
-both Peaceman-Rachford don't converge, but oscillate after finding the main image features
-Peaceman-Rachford RMRS (even RAAR,..., but not AAR RSRM) iterates all seem to satisfy the support constraint, in the video (, except the last ierate). why? 
This was only true of the projection P_M of a fixed point.
An isolated test case did not show the same observation. Why something else in the video?

-Is there even hope to reconstruct from Fourier data? 
Very tight support constraint is needed to capture sharp edges. 
Fourier data has no information at high frequencies. Thus, we can only reconstruct smooth images from Fourier data.
Added to that, the FFT is a finite approximation of the FT. High frequencies are left out. For e.g. the FFT is not faithful. 
Together with numerical errors

-It is crucial to first tigthen the support in order to exploit available high frequencies data
-(random A) Gaussian DRS + M_TVS handles huge (Poisson) noise better (converges faster) than Poison DRS + M_TVS
-TV1 handles the noise better than other TVS, at least when A is randomly sampled
-they do find a solution to the noiseless problem. 
But with noisy data, satisfying the support constraint seems to prohibit the error to go to zero : Inconsistency. 
They get stucked at good local minima, but not at the solution, not even after initializing locally. 
In fact, when initialized close to the true solution, they stagnate after only few steps. 
The hope was to see DRS outperform AAR in presence of noise. The truth is, The paper only claimed boundedness of the iterates.

-Poisson DRS in OS should = Poisson DRS because A is isometric. It commutes with the projection, since the letter is a minimizer (in L2?)
In reality, Poisson DRS in OS outperforms
-last iterate of Poisson DRS in OS violates the mask. Same and only issue with Poisson DRS. Now, everyone. Further project onto S before plotting
-RMRS performs better than RSRM
-RSRM stagnates near true solution
-Spectral init gives no initial point, missing values. Fix it
-Poisson DRS diverges even locally, while AAR almost does not improve. Fix Poisson. But AAR M_TVS improves
-Gaussian  DRS generally converges faster

Challenges: 
-Is AAR really akin HIO? AAR tends to produce iterates close to the support constraint set and performs bad. same for DRS
-memory issue for 128*128 images, 
to store random matrix A:  Unable to allocate 4.13 GiB for an array with shape (16641, 16641) and data type complex128
to plot (Fourier) iterates : Unable to allocate 15.6 KiB for an array with shape (1001,) and data type complex128

-Git repo: I can't push the changes anymore

----------------------------------------------------------------------------------

Outlook:

-The higher the image resolution, the more does DFT samples. Result should improve with higher image size. Test that.


Observations:
-HIO: sometimes, beta = 0.5 is best

-DFT uses (equidistant) sample values x[n], n = 0, ..., N-1 of signal x(t). 
Sampling can introduce aliasing if the sampling rate is smaller than twice the maximum frequency contained in x(t).

Challenges: 

-jsefo is not a sudoers. when installing tkinter

----------------------------------------------------------------------------------

Outlook:

-Implement the artificial rectangular boundary discussed below.


Observations:

This could be a breakthrough:

-unexpected good retrieval of the cancer cell can be misleading if one thinks that its support is the ellipse. It's not. Worst, its highest values are on its true rectangular outer support. 
This means that we could also improve the reconstruction of the shepp logan, if we modify substitute the object with himself, but included into a thin rectangle at the boundary. 
This new object then has full rectangular support, like the cancer cell. In this setting, our rectangular mask is always very effective.
Experimentally, this could mean, letting the beam go through some additional external rectangular window. (not only through the one at the center ). 
One paper discussed a (maybe) similar (in spirit) type of mask. 

It is amazing to see how the added artificial rectangular boundary helps reconstruct the true inner object support and object itself.

-rectangular window is retrieved
the ring of gaussian and the disk too (eventhough there is a bit a space to expect translations, it does not happen), up to some TV cleaning
-cameran is more accurately reconstructed than the sheep logan, because the cameraman fills in totally the rectangular box. 
While, the sheep logan has freedom to move within the box. And this yields more bad local minima. shrinkwrapping? circular box?
-spectral init takes 2 minutes for 64*64 images. Not sure if there is improvement in the reconstruction. Test stability (noise)
At least, Object error look very different
-'RMRS AAR_beta': 0.72, 0,5, 0.67 seem optimal in that order
-'RSRM AAR_beta': 0. 67, 0.45 seem optimal
-'RAAR_beta': 1.0 seems optimal
-Gaussian DRS sometimes reconstructs homometric structures. Should give AAR, when rho = 0. Check that
-RMRS = RSRM but don't seem to have the same first Fourier error, whereas having the same object error. strange
Note however that they do not produce the same iterates. their iterates match with each other only inside the mask.(RS linear, proves this)
Still, I does not explain why the object errors look alike(even in a non loglog plotting) 


Challenges: 

-

----------------------------------------------------------------------------------

Outlook:

- Prove equivalence of projections
- proximal of non convex functionals?
- look at shrinkwrapping

Observations:
-Gaussian DRS from paper (without alpha) looks more stable as rho changes. look at their ptytography setting closely
-Gaussian-DRS TVS_M 0.005 with rect supp is the best performing TV

-the support precision is key here. exact support in one of the parts leads to better reconstruction, even if real and imaginary parts come out mixed.
In practice, real part represent the amplitude and imaginary part the phases. Therefore, it makes sense that both must have the same support in the simulations

- The larger is the object support w r t the image size, the more the (periodical replication of the DFT) signal contains high frequencies.
DFT does not sample at frequencies above 0.5. Thus, more pronounced is the difference even at frequencies below 0.5

On the other hand, the smaller is the object support, the fewer are high frequencies in the DFT signal. It is mainly made of low frequency components.
Meanwhile, the AFT notices and reaches the high frequency components of the true signal. The latter

Challenges: 

-


----------------------------------------------------------------------------------

Outlook:

-remove the SiCc plot from overleaf


Observations:

-errors inside the box, All Gaussian DRS converges linearly, even AAR, but with different rates

-Gaussian loss function, though not convex, has subgradient, but locally. Show it by finding the local region (formed of elements with the same phase or sign?).

-Fourier measurements make errors comparison across different parameters, like object-to-image ratio difficult to apprehend, due to many global minima, like the negative signed, negative conjugate,...
Random measurements allow to see the same pick (at ratios around 0.17) without additional global minima effect in the L2 object error.
Correct in-depth phase or switch to random observation to conduct these specific analyses


Challenges: 

-